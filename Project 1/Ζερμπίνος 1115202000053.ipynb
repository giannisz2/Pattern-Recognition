{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuv0sYuMUIsLOq/VjNOvl5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Άσκηση 1**"],"metadata":{"id":"vRgyVH-nzs2m"}},{"cell_type":"markdown","source":["*Ερώτημα 1.1*"],"metadata":{"id":"WI5_2uXR1Ydj"}},{"cell_type":"markdown","source":["Υπολογίζουμε την παράγωγο της $f(x_{1})$ ως εξής: $${\\nabla}f(x) =  \\frac{{\\partial}f(x)}{{\\partial}x_{1}}.$$ Παρατηρούμε ότι $(x-a)^{T}(x-a) = ||{(x-a)}||^{2}$ .  \n","Επομένως: $f(x) = (x-a)^{T}A(x-a) = ||{x-a}||^{2}A$. Άρα για $x_{1}$ για παράδειγμα έχουμε: $$\\frac{\\partial f(x)}{\\partial x_{1}} = \\frac{\\partial f||x_{1}-a||^{2}A}{\\partial x_{1}} = A\\frac{\\partial ||x_{1}-a||^{2}}{\\partial x_{1}} = 2A(x_{1}-a)\n","$$ Παρόμοια για $x_{i}, i = 2 ...n$."],"metadata":{"id":"g8M5CBN701hY"}},{"cell_type":"markdown","source":["*Ερώτημα 1.2*"],"metadata":{"id":"i-MXmy1H3WRt"}},{"cell_type":"markdown","source":["Υπολογίζουμε το $min_{X}||A-XB||_{F}^{2}$ που είναι η ευκλείδια νόρμα, επομένως κυρτή, συνεχής και παραγωγίσιμη συνάρτηση, με τον εξής τύπο: $$ \\hat{W}_{LS} = YX^{\\dagger}$$ που υπολογίζεται ως εξής: $$ \\hat{W}_{LS} = YX^{\\dagger} = Y(X^{T}X)^{-1}X^{T}$$"],"metadata":{"id":"Hwg62WUf3cOt"}},{"cell_type":"markdown","source":[],"metadata":{"id":"rw5rjf-JNdAi"}},{"cell_type":"markdown","source":["# **Άσκηση 2**\n"],"metadata":{"id":"QPSKcBrF_vct"}},{"cell_type":"markdown","source":["*Ερώτημα 2.1 Model 1*"],"metadata":{"id":"8qa7jkSheJRi"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_cost_history(cost_history):\n","    plt.plot(cost_history)\n","    plt.xlabel('Iterations')\n","    plt.ylabel('Cost')\n","    plt.title('Cost History')\n","    plt.grid(True)\n","    plt.show()\n","\n","def plot_data_and_model(x, y, w0, w1):\n","    plt.scatter(x, y, color='blue', label='Training Data')\n","    x_values = np.linspace(np.min(x), np.max(x), 90000)\n","    y_values = 1 / (1 + np.exp(-(w0 + w1*x)))\n","    y_values = np.tile(y_values,(90000,1))\n","    plt.plot(x_values, y_values, color='red', label='Model')\n","    plt.xlabel('x')\n","    plt.ylabel('y')\n","    plt.title('Data and Model')\n","    plt.grid(True)\n","    plt.show()\n","\n","def gradient_descent(x, y, w0, w1, learning_rate, iterations):\n","  n = float(len(x)) # Number of samples\n","  cost_graph = []\n","  for i in range(iterations):\n","\n","    y_predicted = 1 / (1 + np.exp(-(w0 + w1*x))) # f(x:w)\n","\n","    # Derivatives of cost function with respect to w0 and w1\n","    w1_der = sum(x * (y * np.log2(1/np.exp(-w0-w1*x)) -2*y + 1)/ ((np.exp(w0+w1*x) + 1) * (1 - np.log2(1/np.exp(-w0-w1*x)))),1)\n","    w0_der = sum((y * np.log2(1/np.exp(-w0-w1*x)) -2*y + 1)/ ((np.exp(w0+w1*x) + 1) * (1 - np.log2(1/np.exp(-w0-w1*x)))),1)\n","\n","    # Update step\n","    w1 = w1 - (learning_rate * w1_der)\n","    w0 = w0 - (learning_rate * w0_der)\n","    y_predicted = np.clip(y_predicted, 1e-15, 1 - 1e-15) # Fix edge cases for division with 0 error\n","    cost_f = - np.mean(y * np.log2(y_predicted) + (1-y)* np.log2(1 - y_predicted)) # Cost function\n","    cost_graph.append(cost_f)\n","\n","  print(f\"iteration {i+1}: w1 {w1}, w0 {w0}, cost {cost_f}\")\n","\n","  return w0, w1, cost_graph\n","\n","\n","data1 = np.array([[ 10.63415642, -10.31804897,  -3.91323692,  13.47455445,\n","         12.00245098,   7.01459213, -11.5083141 ,   7.83875   ,\n","        -11.21021617,   6.95282804,   7.79101979,  13.94835343,\n","          3.01243432,  11.67679791,  13.41197807,  14.61995534,\n","         -8.70743264, -14.10312612, -11.68244994,  14.75202699,\n","          9.25316629,  -4.82661632,  -6.99915042,   6.49562369,\n","        -11.46126563,  -9.38897405,  -3.68953244,  -5.95603391,\n","        -10.80285714, -11.78004227],\n","        [  1.        ,   0.        ,   0.        ,   1.        ,\n","          1.        ,   1.        ,   0.        ,   1.        ,\n","          0.        ,   1.        ,   1.        ,   1.        ,\n","          1.        ,   1.        ,   1.        ,   1.        ,\n","          0.        ,   0.        ,   0.        ,   1.        ,\n","          1.        ,   0.        ,   0.        ,   1.        ,\n","          0.        ,   0.        ,   0.        ,   0.        ,\n","          0.        ,   0.        ]])\n","\n","x = data1[0]\n","y = data1[1]\n","w0 = 0.\n","w1 = 1.\n","\n","w0, w1, cost_history = gradient_descent(x, y, w0, w1, 0.001, 150)\n","\n","print(\"Learning rate = 10^(-3)\")\n","plot_cost_history(cost_history)\n","print(\"\\n\")\n","plot_data_and_model(x, y, w0, w1)\n","\n","print(\"\\n\\n\")\n","\n","print(\"Learning rate = 10^(-4)\")\n","w0, w1, cost_history = gradient_descent(x, y, w0, w1, 0.0001, 150)\n","plot_cost_history(cost_history)\n","print(\"\\n\")\n","plot_data_and_model(x, y, w0, w1)"],"metadata":{"id":"gAoMt8c1AAMk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Δεν παρατηρείται κάποια διαφορά μεταξύ learning_rate = 0.001 και 0.0001"],"metadata":{"id":"JygZcSH1hbBU"}},{"cell_type":"markdown","source":["*Ερώτημα 2.1 Model 2*"],"metadata":{"id":"NRsmEK3jeQAC"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def sigma(x):\n","    return x\n","\n","\n","def plot_cost_history(cost_history):\n","    plt.plot(cost_history)\n","    plt.xlabel('Iterations')\n","    plt.ylabel('Cost')\n","    plt.title('Cost History')\n","    plt.grid(True)\n","    plt.show()\n","\n","def plot_data_and_model(x, y, w0, w1, w2, w3):\n","    plt.scatter(x, y, color='blue', label='Training Data')\n","    x_values = np.linspace(np.min(x), np.max(x), 30)\n","    y_values = w0 + w1 * sigma(w2+w3*x)\n","    plt.plot(x_values, y_values, color='red', label='Model')\n","    plt.xlabel('x')\n","    plt.ylabel('y')\n","    plt.title('Data and Model')\n","    plt.grid(True)\n","    plt.show()\n","\n","def gradient_descent(x, y, w0, w1, w2, w3, learning_rate, iterations):\n","  n = float(len(x))\n","  cost_history = []\n","  for i in range(iterations):\n","    y_predicted = w0 + w1 * sigma(w2+w3*x)\n","\n","    w3_der = -(2/n) * sum((y - y_predicted) * sigma(w2 + w3*x)) # overflow\n","    w2_der = -(2/n) * sum((y - y_predicted) * w1*sigma(w3*x))\n","    w1_der = -(2/n) * sum(sigma(w2+ w3*x) * (y - y_predicted))\n","    w0_der = -(2/n) * sum(y - y_predicted)\n","\n","    w3 = w3 - (learning_rate * w3_der)\n","    w2 = w2 - (learning_rate * w2_der)\n","    w1 = w1 - (learning_rate * w1_der)\n","    w0 = w0 - (learning_rate * w0_der)\n","    y_predicted = np.clip(y_predicted, 1e-15, 1 - 1e-15)\n","    cost_f = np.mean((y - y_predicted)**2)\n","    cost_history.append(cost_f)\n","\n","  print(f\"i {i+1}: w3 {w3} w2 {w2} w1 {w1}, w0 {w0} cost {cost_f}\")\n","\n","  return w0, w1, w2, w3, cost_history\n","\n","\n","data2 = np.array([[-6.63823962e-01,  1.76259595e+00, -3.99908500e+00,\n","        -1.58133942e+00, -2.82595287e+00, -3.26129124e+00,\n","        -2.50991831e+00, -1.23551418e+00, -8.25860206e-01,\n","         3.10533872e-01, -6.46443885e-01,  1.48175600e+00,\n","        -2.36438200e+00,  3.02493949e+00, -3.78089925e+00,\n","         1.36374008e+00, -6.61561581e-01,  4.69518628e-01,\n","        -2.87690449e+00, -2.41518809e+00,  2.40595655e+00,\n","         3.74609261e+00, -1.49260657e+00,  1.53858093e+00,\n","         3.01111322e+00,  3.15685331e+00, -3.31964631e+00,\n","        -3.68756173e+00, -2.64135664e+00,  3.02514003e+00],\n","       [-7.76859909e-02,  6.84885863e+00,  2.11068734e-02,\n","         2.91407607e-01, -5.50309589e-01,  5.72361855e-01,\n","         4.50795360e-01,  2.51247169e-01,  4.50427975e-01,\n","         2.58973769e+00, -7.76767080e-04,  5.97738329e+00,\n","        -1.33944040e-01,  1.13399962e+01, -3.45830376e-01,\n","         5.89284348e+00, -3.28271093e-01,  2.98595306e+00,\n","        -3.35623065e-01, -6.33229946e-03,  8.65921447e+00,\n","         1.33554857e+01,  8.29901089e-01,  6.98676486e+00,\n","         1.09374219e+01,  1.10267454e+01, -3.73579147e-01,\n","         8.46227301e-01,  2.54038774e-02,  1.07569223e+01]])\n","data2\n","\n","x = data1[0]\n","y = data1[1]\n","w0 = 0.5\n","w1 = 1.\n","w2 = 2.2\n","w3 = 3.4\n","\n","print(\"Learning rate = 10^(-3)\")\n","w0, w1, w2, w3, cost_history = gradient_descent(x, y, w0, w1, w2, w3, 0.001, 150)\n","plot_cost_history(cost_history)\n","print(\"\\n\")\n","plot_data_and_model(x,y,w0,w1,w2,w3)\n","\n","print(\"\\n\\n\")\n","\n","print(\"Learning rate = 10^(-4)\")\n","w0, w1, w2, w3, cost_history = gradient_descent(x, y, w0, w1, w2, w3, 0.0001, 150)\n","plot_cost_history(cost_history)\n","print(\"\\n\")\n","plot_data_and_model(x,y,w0,w1,w2,w3)"],"metadata":{"id":"-FHYlSPpeSbe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Ερώτημα 2.2 Model 1*"],"metadata":{"id":"K8XxrGbgo06X"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_cost_history(cost_history):\n","    plt.plot(cost_history)\n","    plt.xlabel('Iterations')\n","    plt.ylabel('Cost')\n","    plt.title('Cost History')\n","    plt.grid(True)\n","    plt.show()\n","\n","def plot_data_and_model(x, y, w0, w1):\n","    plt.scatter(x, y, color='blue', label='Training Data')\n","    x_values = np.linspace(np.min(x), np.max(x), 30)\n","    y_values = 1 / (1 + np.exp(-(w0 + np.dot(w1,x.T))))\n","    plt.plot(x_values, y_values, color='red', label='Model')\n","    plt.xlabel('x')\n","    plt.ylabel('y')\n","    plt.title('Data and Model')\n","    plt.grid(True)\n","    plt.show()\n","\n","def gradient_descent(x, y, w0, w1, learning_rate, iterations):\n","  n = float(len(x)) # Number of samples\n","  cost_graph = []\n","  for i in range(iterations):\n","    if i == 99:\n","      learning_rate = 5 * 1e-4\n","    if i == 139:\n","      learning_rate = 1e-4\n","\n","    y_predicted = 1 / (1 + np.exp(-(w0 + np.dot(w1,x)))) # f(x:w)\n","\n","    # Derivatives of cost function with respect to w0 and w1\n","    w1_der = sum(x * (y * np.log2(1/np.exp(-w0-np.dot(w1,x))) -2*y + 1)/ ((np.exp(w0+np.dot(w1,x)) + 1) * (1 - np.log2(1/np.exp(-w0-np.dot(w1,x))))),1)\n","    w0_der = sum((y * np.log2(1/np.exp(-w0-np.dot(w1,x))) -2*y + 1)/ ((np.exp(w0+np.dot(w1,x)) + 1) * (1 - np.log2(1/np.exp(-w0-np.dot(w1,x))))),1)\n","\n","    # Update step\n","    w1 = w1 - (learning_rate * w1_der)\n","    w0 = w0 - (learning_rate * w0_der)\n","    y_predicted = np.clip(y_predicted, 1e-15, 1 - 1e-15) # Fix edge cases for division with 0 error\n","    cost_f = - np.mean(y * np.log2(y_predicted) + (1-y)* np.log2(1 - y_predicted)) # Cost function\n","    cost_graph.append(cost_f)\n","\n","  print(f\"iteration {i+1}: w1 {w1}, w0 {w0}, cost {cost_f}\")\n","\n","  return w0, w1, cost_graph\n","\n","\n","data1 = np.array([[ 10.63415642, -10.31804897,  -3.91323692,  13.47455445,\n","         12.00245098,   7.01459213, -11.5083141 ,   7.83875   ,\n","        -11.21021617,   6.95282804,   7.79101979,  13.94835343,\n","          3.01243432,  11.67679791,  13.41197807,  14.61995534,\n","         -8.70743264, -14.10312612, -11.68244994,  14.75202699,\n","          9.25316629,  -4.82661632,  -6.99915042,   6.49562369,\n","        -11.46126563,  -9.38897405,  -3.68953244,  -5.95603391,\n","        -10.80285714, -11.78004227],\n","        [  1.        ,   0.        ,   0.        ,   1.        ,\n","          1.        ,   1.        ,   0.        ,   1.        ,\n","          0.        ,   1.        ,   1.        ,   1.        ,\n","          1.        ,   1.        ,   1.        ,   1.        ,\n","          0.        ,   0.        ,   0.        ,   1.        ,\n","          1.        ,   0.        ,   0.        ,   1.        ,\n","          0.        ,   0.        ,   0.        ,   0.        ,\n","          0.        ,   0.        ]])\n","\n","x = data1[0]\n","y = data1[1]\n","w0 = 0.\n","w1 = 1.\n","\n","w0, w1, cost_history = gradient_descent(x, y, w0, w1, 0.001, 150)\n","\n","plot_cost_history(cost_history)\n","print(\"\\n\")\n","plot_data_and_model(x, y, w0, w1)"],"metadata":{"id":"pXWS3Y0lo7AP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Παρατηρούμε μια αλλαγή στην κλίση του κόστους γιατί το learning rate μειώνεται άρα θα είναι πιο ακριβής η μέτρηση."],"metadata":{"id":"dEr6S1_Ru0NI"}},{"cell_type":"markdown","source":["*Ερώτημα 2.2 Model 2*"],"metadata":{"id":"cvgDg5_isl_9"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def sigma(x):\n","    return x\n","\n","\n","def plot_cost_history(cost_history):\n","    plt.plot(cost_history)\n","    plt.xlabel('Iterations')\n","    plt.ylabel('Cost')\n","    plt.title('Cost History')\n","    plt.grid(True)\n","    plt.show()\n","\n","def plot_data_and_model(x, y, w0, w1, w2, w3):\n","    plt.scatter(x, y, color='blue', label='Training Data')\n","    x_values = np.linspace(np.min(x), np.max(x), 30)\n","    y_values = w0 + w1 * sigma(w2+w3*x)\n","    plt.plot(x_values, y_values, color='red', label='Model')\n","    plt.xlabel('x')\n","    plt.ylabel('y')\n","    plt.title('Data and Model')\n","    plt.grid(True)\n","    plt.show()\n","\n","def gradient_descent(x, y, w0, w1, w2, w3, learning_rate, iterations):\n","  n = float(len(x))\n","  cost_history = []\n","  for i in range(iterations):\n","    if i == 99:\n","      learning_rate = 5 * 1e-4\n","    if i == 139:\n","      learning_rate = 1e-4\n","    y_predicted = w0 + w1 * sigma(w2+w3*x)\n","\n","    w3_der = -(2/n) * sum((y - y_predicted) * w3*w1*sigma(w2 + w3*x))\n","    w2_der = -(2/n) * sum((y - y_predicted) * w1*sigma(w3*x))\n","    w1_der = -(2/n) * sum(sigma(w2+ w3*x) * (y - y_predicted))\n","    w0_der = -(2/n) * sum(y - y_predicted)\n","\n","    w3 = w3 - (learning_rate * w3_der)\n","    w2 = w2 - (learning_rate * w2_der)\n","    w1 = w1 - (learning_rate * w1_der)\n","    w0 = w0 - (learning_rate * w0_der)\n","    y_predicted = np.clip(y_predicted, 1e-15, 1 - 1e-15)\n","    cost_f = np.mean((y - y_predicted)**2)\n","    cost_history.append(cost_f)\n","\n","  print(f\"i {i+1}: w3 {w3} w2 {w2} w1 {w1}, w0 {w0} cost {cost_f}\")\n","\n","  return w0, w1, w2, w3, cost_history\n","\n","\n","data2 = np.array([[-6.63823962e-01,  1.76259595e+00, -3.99908500e+00,\n","        -1.58133942e+00, -2.82595287e+00, -3.26129124e+00,\n","        -2.50991831e+00, -1.23551418e+00, -8.25860206e-01,\n","         3.10533872e-01, -6.46443885e-01,  1.48175600e+00,\n","        -2.36438200e+00,  3.02493949e+00, -3.78089925e+00,\n","         1.36374008e+00, -6.61561581e-01,  4.69518628e-01,\n","        -2.87690449e+00, -2.41518809e+00,  2.40595655e+00,\n","         3.74609261e+00, -1.49260657e+00,  1.53858093e+00,\n","         3.01111322e+00,  3.15685331e+00, -3.31964631e+00,\n","        -3.68756173e+00, -2.64135664e+00,  3.02514003e+00],\n","       [-7.76859909e-02,  6.84885863e+00,  2.11068734e-02,\n","         2.91407607e-01, -5.50309589e-01,  5.72361855e-01,\n","         4.50795360e-01,  2.51247169e-01,  4.50427975e-01,\n","         2.58973769e+00, -7.76767080e-04,  5.97738329e+00,\n","        -1.33944040e-01,  1.13399962e+01, -3.45830376e-01,\n","         5.89284348e+00, -3.28271093e-01,  2.98595306e+00,\n","        -3.35623065e-01, -6.33229946e-03,  8.65921447e+00,\n","         1.33554857e+01,  8.29901089e-01,  6.98676486e+00,\n","         1.09374219e+01,  1.10267454e+01, -3.73579147e-01,\n","         8.46227301e-01,  2.54038774e-02,  1.07569223e+01]])\n","data2\n","\n","x = data1[0]\n","y = data1[1]\n","w0 = 0.5\n","w1 = 1.\n","w2 = 2.2\n","w3 = 3.4\n","\n","w0, w1, w2, w3, cost_history = gradient_descent(x, y, w0, w1, w2, w3, 0.001, 150)\n","plot_cost_history(cost_history)\n","print(\"\\n\")\n","plot_data_and_model(x,y,w0,w1,w2,w3)"],"metadata":{"id":"lb-iSaojsteX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Άσκηση 3**"],"metadata":{"id":"dro2rMFC0kiv"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","import numpy as np\n","import random\n","\n","\n","# Ερώτημα 1\n","def loadImages(path, image_set):\n","    if image_set == \"Set_1\":\n","        start = 1\n","        end = 7\n","    elif image_set == \"Set_2\":\n","        start = 8\n","        end = 19\n","    elif image_set == \"Set_3\":\n","        start = 20\n","        end = 31\n","    elif image_set == \"Set_4\":\n","        start = 32\n","        end = 45\n","    elif image_set == \"Set_5\":\n","        start = 46\n","        end = 64\n","    else:\n","        print(\"Error.Invalid set_number.\")\n","        return -1, -1\n","\n","    images = []\n","    labels = []\n","\n","    # Read images\n","    for i in range(start, end + 1):\n","        image_path = f\"{path}/person{person:02d}_{i:02d}.png\"\n","        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","        images.append(image.flatten()) # Convert image to one vector (2500,)\n","        labels.append(person) # Add label\n","\n","    # Μετατροπή των λιστών σε numpy arrays\n","    images = np.array(images)\n","    labels = np.array(labels)\n","\n","    return images, labels\n","\n","drive.mount('/content/drive')\n","path = '/content/drive/My Drive/faces'\n","\n","\n","for person in range(10):\n","  person += 1\n","  images, labels = loadImages(path, f\"Set_{1}\")\n","  print(images, labels)\n","\n","  num_im = len(images)\n","\n","  plt.figure(figsize=(15, 5))  # Adjust the figure size to accommodate the row layout\n","\n","  # Plot each image in a single row\n","  for i in range(num_im):\n","    plt.subplot(1, num_im, i+1)\n","    plt.imshow(images[i].reshape(50, 50), cmap='gray')  # Reset dimensions and plot the i-th image\n","    plt.title(f'Label: {labels[i]}')\n","\n","  plt.tight_layout()\n","  plt.show()\n","\n","\n","\n","\n","\n","# Ερώτημα 2\n","# Load image from data set\n","images, labels = loadImages(path, \"Set_1\")\n","\n","pca = PCA(7)\n","pca.fit(images) # Train\n","\n","d = 30\n","eigenfaces = pca.components_[:d] # First 30 components\n","\n","random_image = images[:, random.randint(0, 7)]\n","\n","# Image reconstruction\n","reconstructed_image = np.dot(eigenfaces.T, random_image)\n","\n","# plt.subplot(1, 2, 2)\n","# plt.imshow(reconstructed_image.reshape(50, 50), cmap='gray')\n","# plt.title('Reconstructed Image with Eigenfaces (d=30)')\n","\n","# plt.tight_layout()\n","# plt.show()\n","\n","# Παρατηρήσεις: Υποτίθεται ότι όσο αυξάνεται το d η ανακατασκευή πρέπει να είναι καλύτερη αλλά κάτι έχω κάνει λάθος.\n","\n","\n","\n","\n","\n","# Ερώτημα 3\n","images, labels = loadImages(path, \"Set_1\")\n","\n","rec_errors = []\n","\n","for d in range(7):\n","    d += 1\n","    pca = PCA(d)\n","    pca.fit(images)\n","    eigenfaces = pca.components_\n","    X_rec = np.dot(pca.transform(images), eigenfaces) + pca.mean_\n","    error = np.linalg.norm(images - X_rec)\n","    error = np.mean(error)\n","    rec_errors.append(error)\n","\n","plt.plot((1,1,1,1,1,1,1), rec_errors, marker='o', linestyle='-')\n","plt.xlabel('Number of components (d)')\n","plt.ylabel('Mean reconstruction error')\n","plt.title('Mean Reconstruction Error vs. Number of Components')\n","plt.show()\n","\n","print(\"\\n\")\n","\n","\n","\n","\n","\n","# Ερώτημα 4\n","pca = PCA(7)\n","pca.fit(images)\n","\n","plt.figure(figsize=(8, 8))\n","for i in range(7):\n","    plt.subplot(3, 3, i + 1)\n","    eigenvector = pca.components_[i].reshape(50, 50)\n","    plt.imshow(eigenvector, cmap='gray')\n","    plt.title(f'Eigenvector {i+1}')\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()\n","\n","\n","\n","\n","\n","# Ερώτημα 7\n","print(\"\\n\\ν\")\n","\n","# Apply SVD\n","U, S, V_T = np.linalg.svd(images)\n","\n","plt.figure(figsize=(8, 8))\n","for i in range(7):\n","    plt.subplot(3, 3, i + 1)\n","    singular_vector = V_T[i].reshape(50, 50)\n","    plt.imshow(singular_vector, cmap='gray')\n","    plt.title(f'Singular Vector {i+1}')\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"5lkoVUP90o5G"},"execution_count":null,"outputs":[]}]}